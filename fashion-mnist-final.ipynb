{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST is a drop-in replacement for the very well known, machine learning hello world, MNIST dataset. It has same number of training and test examples and the images have the same 28x28 size and there are a total of 10 classes/labels, you can read more about the dataset here : [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "\n",
    "In this post we will be trying out a couple of different models to and compare their results:\n",
    "\n",
    "## List of models\n",
    "\n",
    "1. 2 Layer Neural Netwoek\n",
    "2. CNN with 1 Convolutional Layer\n",
    "3. CNN with 3 Convolutional Layers\n",
    "4. VGG Like Model\n",
    "5. VGG Like Model With Batchnorm\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "I split the original training data into 80% training and 20% validation. This helps to see weather we're overfitting on the training data and weather we should lower the learning rate and train for more epochs if validation accuarcy is higher than training accuarcy or stop overtraining if training accuarcy shift higher than the validation.\n",
    "\n",
    "To be consistend here, all the models are initially trained for 10 epochs and another 10 epochs with a lower learning late. After the initial 20 epochs, I added data augmentation, which generates new training samples by rotating, shifting and zooming on the training samples, and trained for another 50 epochs.\n",
    "\n",
    "Also, to avoid hot encoding the labels, I decided to use `sparse_categorical_crossentropy` when compiling the models.\n",
    "\n",
    "## Observations\n",
    "All the models achieved a higher accuracy after using data augmentation. Almost always use data augmentation !!\n",
    "\n",
    "\n",
    "## Fun Fact\n",
    "\n",
    "If you uncomment the code in **Drop-in Replacement you said?** section, you'll be able to run all the models on MNIST instead of Fashion-MNIST.\n",
    "It is much easier to get +99.5% results on MNIST. However, as you can see by running the models on both datasets, it gets relatively harder to squeeze accuary on the Fashion-MNIST dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Load Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop-in Replacement you said?\n",
    "As I said at the beginning, fashion MNIST is drop-in replacement for MNINT. In case you want to run all these models on MNIST and compare the results. Uncomment the next section and everything should work automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# (X_train_orig, y_train_orig), (X_test, y_test) = mnist.load_data()\n",
    "# X_train_orig = X_train_orig.reshape(60000, 784)\n",
    "# X_test = X_test.reshape(10000, 784)\n",
    "# X_train_orig = X_train_orig.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train_orig /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7febae3da908>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFJ9JREFUeJzt3W1sneV5B/D/dY6P7cSxcZw4jklMIJC1DSBC8cLrtlQB\nCogJ2g8IJtF0oAZprCoSH8ZAU9mnomm0YuvEmo6UULW0k1oEqqAdyaYiaAcYFF6S8BLALE7iOIlJ\n4pcc+7xc++AHZMDPdR/O23PM9f9JUexz+Tnn9pP8fY7P9dz3LaoKIvInlfQAiCgZDD+RUww/kVMM\nP5FTDD+RUww/kVMMP5FTDD+RUww/kVNN9XywZmnRVrTV8yEbgwTqNbzIMr/UPt8dyybMerZg/xdp\nkuJnHtOHpt8o/9iSWOf9c3phaxYTmNap0P84ABWGX0SuAvAAgDSA/1DV+6yvb0UbLpSNlTzkvCRN\n9mnWQsG+gwouwT769YvN+sa/+aNZ33NiuVlf0mL/8EgZKRu6aNw8tlLWea/lOU/S87qj5K8t+2W/\niKQB/BuAqwGsBXCTiKwt9/6IqL4q+Z1/PYC9qvquqk4D+AWA66ozLCKqtUrCvwLAvlmfD0W3fYyI\nbBaRAREZyGGqgocjomqq+bv9qrpFVftVtT+Dllo/HBGVqJLw7wfQN+vzldFtRDQPVBL+FwGsEZEz\nRKQZwI0AnqjOsIio1spu9alqXkT+FsDvMNPq26qqu6o2skaTSseWJB1fAwDNTVd7NB+T7u6OrQ38\n44Pmsa9OZ816ttP+3tKBhvkFLc2xtbN+/k3z2DP/aqdZD9F8vuxjpcX+FVWn5v/7VxX1+VX1SQBP\nVmksRFRHvLyXyCmGn8gphp/IKYafyCmGn8gphp/IKannjj0d0qWJTek1+vQAAA3MLa/heRq+4xKz\n/pWbXzDrtyx5tuzHzqp9Xpphn5cWsafGpiX+vBXUnnZ+oNBu1h8YusKsj32vL7bW/NsXzWODJDBl\nPqEpwc/rDpzQ0ZLm8/OZn8gphp/IKYafyCmGn8gphp/IKYafyCk/rb4aeutHf2rWf3L5Q2Z9bfOY\nWT9asDs3hwqLYmutkjOPPVFsNev/fmCDWT+t7QOzfnPXH2Jrx4oLzGND+ppOmPWMMd34uweuMY89\nckuPWS/sedusSyZ+KjNQu2nebPURURDDT+QUw0/kFMNP5BTDT+QUw0/kFMNP5JSfPn+FUzDf2tof\nW9t55b+axz41capZLwR+BrenTpp1y5K0vRPuOc32EtTv5eyxZQJbdK801od+P2//m+ye6g08tj2d\nuGDs0X1u80Hz2N9N2HvOPnV2p1lPCvv8RBTE8BM5xfATOcXwEznF8BM5xfATOcXwEzlVUZ9fRAYB\njAEoAMiranwzHPN7Pv/Vu47F1pY3HTePnQ4sj92asufcZ4uZio63hLbYbkvZ1wF0pibN+v784tha\nLnBeugPz9UOG8/G9+EO5U8xj/6LtDbP+1z+8w6z33h+/jkEtfZY+f0VbdEe+oqpHqnA/RFRHfNlP\n5FSl4VcA20XkJRHZXI0BEVF9VPqy/zJV3S8iywA8LSJvqOozs78g+qGwGQBasbDChyOiaqnomV9V\n90d/jwB4DMD6Ob5mi6r2q2p/Bi2VPBwRVVHZ4ReRNhFp//BjAFcCeL1aAyOi2qrkZX8PgMdkZqps\nE4Cfq+pvqzIqIqq5ssOvqu8COK+KY0lUU99Ks/7lBTtjawdy8b1sAOhIZ816aL5+NmX3+XMa/88Y\nusYgq/Z9Zwt2fThv98sXGtcJpAJrARwrtJn1o8Z+BYB9jcKiwL9J6PqHyQvs6xvmA7b6iJxi+Imc\nYviJnGL4iZxi+ImcYviJnKrGrL7PhSMb+sz68vREbO1wvsM8tq9p1Kz/78kzzXpoWm17Kr5tFWpZ\nNQfue6JoX5VZUPv5o9lYXjvUhpwo2ttcr8jY5/VoPr4V2Gn8ewJAS2BZ8O7F9rbq8wGf+YmcYviJ\nnGL4iZxi+ImcYviJnGL4iZxi+ImcYp8/MnKx3dfNGP1yaytoAOhrspfWfiewRHVoaqvVD8+q3Stv\nlrxZD22DnQkcf6wQv3Rb6BqCVrHP2yuTq8z66paR2Fro2okDhXazvqrjA7NuVxsDn/mJnGL4iZxi\n+ImcYviJnGL4iZxi+ImcYviJnGKfP9J+qj0/Oxfo5VsWib389dnNw2Z90NjmGrDnrYf6+CnYy2eH\nttEOse6/GFgLIJOyx2718QHg3JYDsbV9xvbdQHhJ879c+opZfwT2+hCNgM/8RE4x/EROMfxETjH8\nRE4x/EROMfxETjH8RE4F+/wishXAtQBGVPWc6LYuAL8EcDqAQQA3qOp8mMIc68Le/zPrWaPfPRmY\nlz6ldr+6K2X32sdS9hrzE6n4x7fWzQfCc+pzxcqeHwrG84u1fTcAtKWmA3X7eEtozwBr23MAuLZt\nyKx/Xvr8DwO46hO33QVgh6quAbAj+pyI5pFg+FX1GQCf3BrlOgDboo+3Abi+yuMiohor9zVdj6oe\njD4eBtBTpfEQUZ1U/IafqioQv8CdiGwWkQERGcih/N/RiKi6yg3/IRHpBYDo79gZFqq6RVX7VbU/\nA/vNJSKqn3LD/wSATdHHmwA8Xp3hEFG9BMMvIo8C+COAL4jIkIjcCuA+AFeIyNsALo8+J6J5JNjn\nV9WbYkobqzyWRG3s3G3WrT5/aE78hNr1qfgtAQAAI4E15NPGngKhfnaoVx66DiAd+N7TEl8vBObz\nHy3Er1MAAAdy9joH1nUEoT0BQtdunJJaYNZTra1mvZjNmvV64BV+RE4x/EROMfxETjH8RE4x/ERO\nMfxETnHp7sjaloNmfbIYv5RzaNpsV8reJvtI0Z66GmpLWe200NTUkI7USbMeagWG2nmVOCVtT3Xu\nS4/H1g4gfutwADhc6ChrTB+avuRss9703y9VdP/VwGd+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+\nIqfY5490B7aDfrcY36tvTdl9+Ldy9pzdszL2P4PVxwfsbbRD041DMoFrGEJTgq1ptaOBKbsZ2P8m\nxwttZv3+kfhZ53cu22Ee+850+VuyA8Bkj73Fd2VXEVQHn/mJnGL4iZxi+ImcYviJnGL4iZxi+Imc\nYviJnHLT50932J3V35+0t1S2+t3Xtx0zjz3rqdvN+t9f+qRZv3TBO2Z91/Ty2Fol21gDQDFwnUAB\ndj/cukahy5hvDwBZtXvlR/L2suQn8vFrDZyRCSwLXojdhAoAsGfaXno7u9h+XmWfn4gSw/ATOcXw\nEznF8BM5xfATOcXwEznF8BM5Fezzi8hWANcCGFHVc6Lb7gXwLQCHoy+7W1XtZnXCjnzdXke9u+k5\ns74vtyS2lhb7Z2jvdvs0T11s97N70navfdDo5YfW1e9I2f3qMWO/AiDcix/Nx/fTQ+sgtAfG1pM5\nbtbfGL0gtpY7zV6nYNeUfd3HFQvfMusTKwP7rjeAUp75HwZw1Ry3/0BV10V/Gjr4RPRpwfCr6jMA\nRuswFiKqo0p+5/+2iLwqIltFZHHVRkREdVFu+B8EsBrAOgAHAdwf94UisllEBkRkIIfKrjMnouop\nK/yqekhVC6paBPBjAOuNr92iqv2q2p+B/eYTEdVPWeEXkd5Zn34NwOvVGQ4R1Usprb5HAWwAsFRE\nhgB8F8AGEVkHQAEMArithmMkohoIhl9Vb5rj5odqMJaaOtltzzsPrU8/XcE+980n7Pv+8oL3zPre\nXKtZX5GO73e/U+w2jw2x1t0HgOmCPafeOj4tdi88tF/BmsywWR/dE39tRuZ8e9whnSn7RXOhz75G\noRHwCj8ipxh+IqcYfiKnGH4ipxh+IqcYfiKn3CzdPdlb2VbVlShm7DZjf4vdCvzJ8dPN+kUL3o2t\nZcTe5jq0hXdWA23GzAdmvTN1MrYWWvZ799QKs97fYrf6+rbHn9fxG+1WXGjJ88NFu03Z3Gqf90bA\nZ34ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ip9z0+dOnTpr1ycAS160yHVt7Lmv3yjPjdh+/Rezl\nr0NjyxrTjVvFXh47B3tqaxp2P3s432nWj0r80t3ZwLLgQ9NdZn1lh72Ndnoq/ry/mbOf97rTJ8z6\nYM7+vlOp5K4rKRWf+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcctPn72yPn1deimVNY7G1Hx3a\nYB7b8uLbFT12qB8+UmiPrYXmpYfuO6f2dQCh47OIr4fuuzdzzKyHtLx3JLa2fdzesv2ytjfNemjr\n8862yv6/1QOf+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcCvb5RaQPwCMAegAogC2q+oCIdAH4\nJYDTAQwCuEFV7UXcE9TWHD8fHwCyaver+5pGY2vP7T3TPHbNn9hz6kNWt9jz1nPGfP6xov3zfaEE\nrgMIrDXQmrK/N6sf3td81Dz2WKHNrAdNxf+bvzZm7wnw1UWvm/WjGr9OAQDkAluXN4JSnvnzAO5U\n1bUALgJwu4isBXAXgB2qugbAjuhzIponguFX1YOq+nL08RiAPQBWALgOwLboy7YBuL5WgySi6vtM\nv/OLyOkAzgfwPIAeVT0YlYYx82sBEc0TJYdfRBYB+BWAO1T1YwucqaoCcy/2JiKbRWRARAZysH+/\nJKL6KSn8IpLBTPB/pqq/jm4+JCK9Ub0XwJzvSqnqFlXtV9X+DOzJEERUP8Hwi4gAeAjAHlX9/qzS\nEwA2RR9vAvB49YdHRLVSypTeSwHcDOA1EdkZ3XY3gPsA/KeI3ArgfQA31GaI1dGWsVt9IRe0NMfW\nVv3Ubusc+2Jlr3gKgZ/RGcQvUR3agjukqPZjh6b0LmuKXwLbGjcAjBXs7cFDjl+yKra2d4f9fbV/\n4zdm3WqvAoCqvf14IwiGX1WfBWI3Ut9Y3eEQUb3wCj8ipxh+IqcYfiKnGH4ipxh+IqcYfiKn3Czd\n3ZqubFqtJfNfA2b9xD9cUtH9FwI940wqX/Z9T6p9DUJK7OsEVmTsWdxd6fHY2r7cEvPYSo2viL/+\n4rTt9tLaCzeZZbSm7OtGjo/b1yjYm4/XB5/5iZxi+ImcYviJnGL4iZxi+ImcYviJnGL4iZxy0+ef\nzMfPx6+1k6vt5cuG8vG9cABoS3WU/diheefLm+xtsIfznWY9tOT57qn4JbJDaw2kZM6V4Uo2tTi+\nlh63+/QZCVxbEViLQN+vcNnxOuAzP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTbvr8g0ftGdTd\nq+LXlweAyWL5c+aXdo/Z9x2Yr58OzKlvS8VfR9Aq9jUE6bl3WfvIWNGel96eypr1zvRkbO1YYaF5\nbMgLU/YaDcXm+O8tfcDeHjyn9nnJwd6rYekrlV2jUA985idyiuEncorhJ3KK4SdyiuEncorhJ3KK\n4SdyKtjnF5E+AI8A6AGgALao6gMici+AbwE4HH3p3ar6ZK0GWqmTHyww66F579/Z/2dGdcI89p4v\n2KdlYWDe+rTaPWVrTv1Y0f6+Q/cdcjjfbtYXGtcgZMSeEz9RtPcU6DbuGwCml8dfB5A/OGwee6hg\nr1MQ+v/S/r59/UMjKOUinzyAO1X1ZRFpB/CSiDwd1X6gqv9cu+ERUa0Ew6+qBwEcjD4eE5E9AOKX\nZyGieeEz/c4vIqcDOB/A89FN3xaRV0Vkq4jMuWiSiGwWkQERGcjBfplGRPVTcvhFZBGAXwG4Q1VP\nAHgQwGoA6zDzyuD+uY5T1S2q2q+q/RnYv8MRUf2UFH4RyWAm+D9T1V8DgKoeUtWCqhYB/BjA+toN\nk4iqLRh+EREADwHYo6rfn3V776wv+xqA16s/PCKqlVLe7b8UwM0AXhORndFtdwO4SUTWYab9Nwjg\ntpqMsErSC+0puec121NfN/Q9F1v7KtaZx96z9Rtm/Xu3PGzWz8wcNuutRsssFZiy+6XmyqbVhrw0\nFb9Edmi6cGfabqGekVlk1r/4L/HHF9efax57bvPLZv2UlN0qnO60W4WN8AtwKe/2PwtgrgnnDdvT\nJ6IwXuFH5BTDT+QUw0/kFMNP5BTDT+QUw0/klGhgieJq6pAuvVA21u3xZkt32Ntcj13+JbOemo4/\nT62/eaGsMZVKLznPrI+uje/Vn+y2lwWfWmovC24tfw0AmeP280fTRPzjt++zH3vJ74fMen6fXa/E\nkdsuNuvFjH1el/3wD9UcTsme1x04oaP24CJ85idyiuEncorhJ3KK4SdyiuEncorhJ3KK4Sdyqq59\nfhE5DOD9WTctBXCkbgP4bBp1bI06LoBjK1c1x7ZKVbtL+cK6hv9TDy4yoKr9iQ3A0Khja9RxARxb\nuZIaG1/2EznF8BM5lXT4tyT8+JZGHVujjgvg2MqVyNgS/Z2fiJKT9DM/ESUkkfCLyFUi8qaI7BWR\nu5IYQxwRGRSR10Rkp4gMJDyWrSIyIiKvz7qtS0SeFpG3o7/n3CYtobHdKyL7o3O3U0SuSWhsfSLy\nPyKyW0R2ich3otsTPXfGuBI5b3V/2S8iaQBvAbgCwBCAFwHcpKq76zqQGCIyCKBfVRPvCYvInwMY\nB/CIqp4T3fZPAEZV9b7oB+diVf27BhnbvQDGk965OdpQpnf2ztIArgfwTSR47oxx3YAEzlsSz/zr\nAexV1XdVdRrALwBcl8A4Gp6qPgNg9BM3XwdgW/TxNsz856m7mLE1BFU9qKovRx+PAfhwZ+lEz50x\nrkQkEf4VAPbN+nwIjbXltwLYLiIvicjmpAczh55o23QAGAbQk+Rg5hDcubmePrGzdMOcu3J2vK42\nvuH3aZep6joAVwO4PXp525B05ne2RmrXlLRzc73MsbP0R5I8d+XueF1tSYR/P4C+WZ+vjG5rCKq6\nP/p7BMBjaLzdhw99uElq9PdIwuP5SCPt3DzXztJogHPXSDteJxH+FwGsEZEzRKQZwI0AnkhgHJ8i\nIm3RGzEQkTYAV6Lxdh9+AsCm6ONNAB5PcCwf0yg7N8ftLI2Ez13D7XitqnX/A+AazLzj/w6Ae5IY\nQ8y4VgN4JfqzK+mxAXgUMy8Dc5h5b+RWAEsA7ADwNoDtALoaaGw/BfAagFcxE7TehMZ2GWZe0r8K\nYGf055qkz50xrkTOG6/wI3KKb/gROcXwEznF8BM5xfATOcXwEznF8BM5xfATOcXwEzn1/6dWfW1j\nLc8WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febb182da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation='relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 468,874\n",
      "Trainable params: 468,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.6354 - acc: 0.7800 - val_loss: 0.4209 - val_acc: 0.8569\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.4120 - acc: 0.8564 - val_loss: 0.3947 - val_acc: 0.8657\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.3717 - acc: 0.8675 - val_loss: 0.3657 - val_acc: 0.8750\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.3400 - acc: 0.8776 - val_loss: 0.3263 - val_acc: 0.8866\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.3181 - acc: 0.8855 - val_loss: 0.3122 - val_acc: 0.8871\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2965 - acc: 0.8933 - val_loss: 0.3192 - val_acc: 0.8876\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2855 - acc: 0.8953 - val_loss: 0.3082 - val_acc: 0.8907\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2728 - acc: 0.8992 - val_loss: 0.2893 - val_acc: 0.8978\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2608 - acc: 0.9052 - val_loss: 0.3087 - val_acc: 0.8871\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2501 - acc: 0.9067 - val_loss: 0.2865 - val_acc: 0.8967\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2392 - acc: 0.9117 - val_loss: 0.2930 - val_acc: 0.8967\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2289 - acc: 0.9161 - val_loss: 0.2985 - val_acc: 0.8953\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2251 - acc: 0.9173 - val_loss: 0.2922 - val_acc: 0.8960\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2124 - acc: 0.9214 - val_loss: 0.2962 - val_acc: 0.8964\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.2017 - acc: 0.9253 - val_loss: 0.2751 - val_acc: 0.9038\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.1966 - acc: 0.9270 - val_loss: 0.2858 - val_acc: 0.9011\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.1874 - acc: 0.9309 - val_loss: 0.2918 - val_acc: 0.8989\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.1841 - acc: 0.9312 - val_loss: 0.2920 - val_acc: 0.8984\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.1812 - acc: 0.9338 - val_loss: 0.2831 - val_acc: 0.9004\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s - loss: 0.1673 - acc: 0.9381 - val_loss: 0.2984 - val_acc: 0.9013\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.357285452712\n",
      "Test accuracy: 0.8879\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.6535 - acc: 0.7764 - val_loss: 0.4212 - val_acc: 0.8563\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.4004 - acc: 0.8595 - val_loss: 0.3474 - val_acc: 0.8813\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.3477 - acc: 0.8769 - val_loss: 0.3211 - val_acc: 0.8893\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.3228 - acc: 0.8848 - val_loss: 0.2988 - val_acc: 0.8969\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2998 - acc: 0.8940 - val_loss: 0.2789 - val_acc: 0.9033\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2865 - acc: 0.8975 - val_loss: 0.2782 - val_acc: 0.9018\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2721 - acc: 0.9030 - val_loss: 0.2709 - val_acc: 0.9053\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2654 - acc: 0.9036 - val_loss: 0.2531 - val_acc: 0.9102\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2534 - acc: 0.9083 - val_loss: 0.2538 - val_acc: 0.9063\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2481 - acc: 0.9094 - val_loss: 0.2823 - val_acc: 0.8995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb90081fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2361 - acc: 0.9138 - val_loss: 0.2467 - val_acc: 0.9130\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2254 - acc: 0.9188 - val_loss: 0.2436 - val_acc: 0.9139\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2203 - acc: 0.9195 - val_loss: 0.2362 - val_acc: 0.9177\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2104 - acc: 0.9228 - val_loss: 0.2366 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.2070 - acc: 0.9238 - val_loss: 0.2276 - val_acc: 0.9187\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.1971 - acc: 0.9278 - val_loss: 0.2254 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.1913 - acc: 0.9301 - val_loss: 0.2348 - val_acc: 0.9149\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.1860 - acc: 0.9313 - val_loss: 0.2271 - val_acc: 0.9194\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.1809 - acc: 0.9344 - val_loss: 0.2220 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 0s - loss: 0.1735 - acc: 0.9368 - val_loss: 0.2174 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb886660b8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.250880071822\n",
      "Test accuracy: 0.9123\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 7s - loss: 0.5429 - acc: 0.7988 - val_loss: 0.4489 - val_acc: 0.8303\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 6s - loss: 0.4493 - acc: 0.8327 - val_loss: 0.4163 - val_acc: 0.8443\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 6s - loss: 0.4383 - acc: 0.8365 - val_loss: 0.3987 - val_acc: 0.8533\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 6s - loss: 0.4167 - acc: 0.8440 - val_loss: 0.3855 - val_acc: 0.8594\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 6s - loss: 0.4039 - acc: 0.8486 - val_loss: 0.3835 - val_acc: 0.8585\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 6s - loss: 0.4013 - acc: 0.8498 - val_loss: 0.3762 - val_acc: 0.8633\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 6s - loss: 0.3855 - acc: 0.8555 - val_loss: 0.3643 - val_acc: 0.8633\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 6s - loss: 0.3817 - acc: 0.8575 - val_loss: 0.3545 - val_acc: 0.8700\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 6s - loss: 0.3739 - acc: 0.8602 - val_loss: 0.3565 - val_acc: 0.8693\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 6s - loss: 0.3698 - acc: 0.8611 - val_loss: 0.3494 - val_acc: 0.8706\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 6s - loss: 0.3654 - acc: 0.8619 - val_loss: 0.3487 - val_acc: 0.8697\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 6s - loss: 0.3572 - acc: 0.8653 - val_loss: 0.3448 - val_acc: 0.8737\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 6s - loss: 0.3552 - acc: 0.8671 - val_loss: 0.3333 - val_acc: 0.8791\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 6s - loss: 0.3552 - acc: 0.8667 - val_loss: 0.3485 - val_acc: 0.8702\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 6s - loss: 0.3513 - acc: 0.8693 - val_loss: 0.3348 - val_acc: 0.8756\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 6s - loss: 0.3461 - acc: 0.8700 - val_loss: 0.3273 - val_acc: 0.8807\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 6s - loss: 0.3456 - acc: 0.8706 - val_loss: 0.3333 - val_acc: 0.8774\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 6s - loss: 0.3386 - acc: 0.8745 - val_loss: 0.3257 - val_acc: 0.8785\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 6s - loss: 0.3349 - acc: 0.8761 - val_loss: 0.3180 - val_acc: 0.8811\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 6s - loss: 0.3331 - acc: 0.8757 - val_loss: 0.3175 - val_acc: 0.8848\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 6s - loss: 0.3321 - acc: 0.8757 - val_loss: 0.3268 - val_acc: 0.8753\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 6s - loss: 0.3303 - acc: 0.8770 - val_loss: 0.3149 - val_acc: 0.8836\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 6s - loss: 0.3238 - acc: 0.8791 - val_loss: 0.3114 - val_acc: 0.8845\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 6s - loss: 0.3235 - acc: 0.8791 - val_loss: 0.3020 - val_acc: 0.8903\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 6s - loss: 0.3251 - acc: 0.8783 - val_loss: 0.3100 - val_acc: 0.8843\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 6s - loss: 0.3219 - acc: 0.8817 - val_loss: 0.3054 - val_acc: 0.8884\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 6s - loss: 0.3183 - acc: 0.8805 - val_loss: 0.3007 - val_acc: 0.8931\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 6s - loss: 0.3146 - acc: 0.8823 - val_loss: 0.3076 - val_acc: 0.8871\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 6s - loss: 0.3089 - acc: 0.8833 - val_loss: 0.3043 - val_acc: 0.8881\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 6s - loss: 0.3140 - acc: 0.8841 - val_loss: 0.3013 - val_acc: 0.8866\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 6s - loss: 0.3087 - acc: 0.8843 - val_loss: 0.2933 - val_acc: 0.8901\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 6s - loss: 0.3108 - acc: 0.8820 - val_loss: 0.2974 - val_acc: 0.8953\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 6s - loss: 0.3064 - acc: 0.8871 - val_loss: 0.3004 - val_acc: 0.8903\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 6s - loss: 0.3055 - acc: 0.8859 - val_loss: 0.2916 - val_acc: 0.8930\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 6s - loss: 0.3047 - acc: 0.8862 - val_loss: 0.3002 - val_acc: 0.8890\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 6s - loss: 0.3006 - acc: 0.8880 - val_loss: 0.2881 - val_acc: 0.8953\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 6s - loss: 0.3063 - acc: 0.8856 - val_loss: 0.3006 - val_acc: 0.8888\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 6s - loss: 0.2984 - acc: 0.8874 - val_loss: 0.3068 - val_acc: 0.8862\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 6s - loss: 0.3032 - acc: 0.8859 - val_loss: 0.2894 - val_acc: 0.8939\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 6s - loss: 0.2996 - acc: 0.8883 - val_loss: 0.3023 - val_acc: 0.8871\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 6s - loss: 0.3003 - acc: 0.8876 - val_loss: 0.3014 - val_acc: 0.8899\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 6s - loss: 0.2933 - acc: 0.8894 - val_loss: 0.2886 - val_acc: 0.8928\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 6s - loss: 0.2939 - acc: 0.8890 - val_loss: 0.3088 - val_acc: 0.8851\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 6s - loss: 0.2952 - acc: 0.8878 - val_loss: 0.2854 - val_acc: 0.8960\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 6s - loss: 0.2923 - acc: 0.8910 - val_loss: 0.2846 - val_acc: 0.8964\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 6s - loss: 0.2891 - acc: 0.8917 - val_loss: 0.2928 - val_acc: 0.8920\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 6s - loss: 0.2903 - acc: 0.8898 - val_loss: 0.2829 - val_acc: 0.8981\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 6s - loss: 0.2877 - acc: 0.8917 - val_loss: 0.2863 - val_acc: 0.8967\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 6s - loss: 0.2903 - acc: 0.8896 - val_loss: 0.2831 - val_acc: 0.8978\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 6s - loss: 0.2848 - acc: 0.8930 - val_loss: 0.2858 - val_acc: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb546c9b38>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23108966648\n",
      "Test accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with 3 Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.9809 - acc: 0.6365 - val_loss: 0.5820 - val_acc: 0.7757\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.5837 - acc: 0.7796 - val_loss: 0.4740 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.4999 - acc: 0.8146 - val_loss: 0.4217 - val_acc: 0.8484\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.4506 - acc: 0.8331 - val_loss: 0.3986 - val_acc: 0.8590\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.4136 - acc: 0.8469 - val_loss: 0.3570 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3802 - acc: 0.8588 - val_loss: 0.3243 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3668 - acc: 0.8646 - val_loss: 0.3143 - val_acc: 0.8849\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3488 - acc: 0.8702 - val_loss: 0.2980 - val_acc: 0.8918\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3339 - acc: 0.8766 - val_loss: 0.2879 - val_acc: 0.8955\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3243 - acc: 0.8804 - val_loss: 0.2809 - val_acc: 0.8990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb546e0fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.3096 - acc: 0.8857 - val_loss: 0.2743 - val_acc: 0.9002\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2982 - acc: 0.8890 - val_loss: 0.2716 - val_acc: 0.8997\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2944 - acc: 0.8909 - val_loss: 0.2588 - val_acc: 0.9082\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2877 - acc: 0.8941 - val_loss: 0.2554 - val_acc: 0.9077\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2768 - acc: 0.8965 - val_loss: 0.2491 - val_acc: 0.9096\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2711 - acc: 0.8995 - val_loss: 0.2455 - val_acc: 0.9097\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2644 - acc: 0.9017 - val_loss: 0.2513 - val_acc: 0.9086\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2599 - acc: 0.9044 - val_loss: 0.2349 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2551 - acc: 0.9060 - val_loss: 0.2319 - val_acc: 0.9153\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s - loss: 0.2453 - acc: 0.9081 - val_loss: 0.2335 - val_acc: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb156d3d30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.257787227988\n",
      "Test accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 7s - loss: 0.4677 - acc: 0.8254 - val_loss: 0.3842 - val_acc: 0.8568\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 6s - loss: 0.4257 - acc: 0.8413 - val_loss: 0.3541 - val_acc: 0.8660\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 6s - loss: 0.4153 - acc: 0.8453 - val_loss: 0.3463 - val_acc: 0.8733\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 6s - loss: 0.3991 - acc: 0.8506 - val_loss: 0.3464 - val_acc: 0.8717\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 6s - loss: 0.3878 - acc: 0.8551 - val_loss: 0.3366 - val_acc: 0.8730\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 6s - loss: 0.3780 - acc: 0.8588 - val_loss: 0.3250 - val_acc: 0.8806\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 6s - loss: 0.3791 - acc: 0.8592 - val_loss: 0.3206 - val_acc: 0.8789\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 6s - loss: 0.3718 - acc: 0.8615 - val_loss: 0.3215 - val_acc: 0.8813\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 6s - loss: 0.3691 - acc: 0.8623 - val_loss: 0.3182 - val_acc: 0.8836\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 6s - loss: 0.3601 - acc: 0.8652 - val_loss: 0.3113 - val_acc: 0.8838\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 6s - loss: 0.3546 - acc: 0.8660 - val_loss: 0.3052 - val_acc: 0.8872\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 6s - loss: 0.3539 - acc: 0.8680 - val_loss: 0.3009 - val_acc: 0.8883\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 6s - loss: 0.3437 - acc: 0.8707 - val_loss: 0.3040 - val_acc: 0.8858\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 6s - loss: 0.3463 - acc: 0.8689 - val_loss: 0.2934 - val_acc: 0.8889\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 6s - loss: 0.3468 - acc: 0.8702 - val_loss: 0.2987 - val_acc: 0.8901\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 6s - loss: 0.3376 - acc: 0.8729 - val_loss: 0.2883 - val_acc: 0.8935\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 6s - loss: 0.3380 - acc: 0.8738 - val_loss: 0.2931 - val_acc: 0.8932\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 6s - loss: 0.3338 - acc: 0.8760 - val_loss: 0.2919 - val_acc: 0.8910\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 6s - loss: 0.3357 - acc: 0.8749 - val_loss: 0.2833 - val_acc: 0.8953\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 6s - loss: 0.3305 - acc: 0.8776 - val_loss: 0.2789 - val_acc: 0.8959\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 6s - loss: 0.3311 - acc: 0.8757 - val_loss: 0.2913 - val_acc: 0.8944\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 6s - loss: 0.3299 - acc: 0.8770 - val_loss: 0.2860 - val_acc: 0.8914\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 6s - loss: 0.3234 - acc: 0.8789 - val_loss: 0.2869 - val_acc: 0.8956\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 6s - loss: 0.3294 - acc: 0.8776 - val_loss: 0.2874 - val_acc: 0.8915\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 6s - loss: 0.3222 - acc: 0.8796 - val_loss: 0.2835 - val_acc: 0.8950\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 6s - loss: 0.3160 - acc: 0.8819 - val_loss: 0.2751 - val_acc: 0.8989\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 6s - loss: 0.3160 - acc: 0.8837 - val_loss: 0.2840 - val_acc: 0.8929\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 6s - loss: 0.3195 - acc: 0.8794 - val_loss: 0.2767 - val_acc: 0.8956\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 6s - loss: 0.3144 - acc: 0.8839 - val_loss: 0.2840 - val_acc: 0.8968\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 6s - loss: 0.3145 - acc: 0.8811 - val_loss: 0.2778 - val_acc: 0.9019\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 6s - loss: 0.3121 - acc: 0.8837 - val_loss: 0.2781 - val_acc: 0.8992\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 6s - loss: 0.3076 - acc: 0.8851 - val_loss: 0.2711 - val_acc: 0.8990\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 6s - loss: 0.3139 - acc: 0.8833 - val_loss: 0.2679 - val_acc: 0.8989\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 6s - loss: 0.3143 - acc: 0.8815 - val_loss: 0.2708 - val_acc: 0.9010\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 6s - loss: 0.3055 - acc: 0.8855 - val_loss: 0.2700 - val_acc: 0.8994\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 6s - loss: 0.3062 - acc: 0.8864 - val_loss: 0.2654 - val_acc: 0.9036\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 6s - loss: 0.3021 - acc: 0.8865 - val_loss: 0.2655 - val_acc: 0.8998\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 6s - loss: 0.3119 - acc: 0.8831 - val_loss: 0.2629 - val_acc: 0.9020\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 6s - loss: 0.3003 - acc: 0.8877 - val_loss: 0.2636 - val_acc: 0.9029\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 6s - loss: 0.3012 - acc: 0.8873 - val_loss: 0.2561 - val_acc: 0.9063\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 6s - loss: 0.2985 - acc: 0.8885 - val_loss: 0.2719 - val_acc: 0.9000\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 6s - loss: 0.3029 - acc: 0.8868 - val_loss: 0.2680 - val_acc: 0.8973\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 6s - loss: 0.2943 - acc: 0.8905 - val_loss: 0.2607 - val_acc: 0.9025\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 6s - loss: 0.3025 - acc: 0.8880 - val_loss: 0.2619 - val_acc: 0.9014\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 6s - loss: 0.2945 - acc: 0.8889 - val_loss: 0.2552 - val_acc: 0.9069\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 6s - loss: 0.2989 - acc: 0.8878 - val_loss: 0.2603 - val_acc: 0.9040\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 6s - loss: 0.2977 - acc: 0.8886 - val_loss: 0.2552 - val_acc: 0.9050\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 6s - loss: 0.2958 - acc: 0.8883 - val_loss: 0.2574 - val_acc: 0.9062\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 6s - loss: 0.2888 - acc: 0.8942 - val_loss: 0.2915 - val_acc: 0.8916\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 6s - loss: 0.2897 - acc: 0.8912 - val_loss: 0.2569 - val_acc: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb140f4ba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.239840124524\n",
      "Test accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with 4 Convolutional Layers and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.7104 - acc: 0.7530 - val_loss: 1.9009 - val_acc: 0.5357\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.4277 - acc: 0.8448 - val_loss: 1.8746 - val_acc: 0.5033\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.3553 - acc: 0.8730 - val_loss: 1.6118 - val_acc: 0.5543\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.3102 - acc: 0.8877 - val_loss: 0.8439 - val_acc: 0.7046\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.2814 - acc: 0.8984 - val_loss: 0.4175 - val_acc: 0.8534\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.2582 - acc: 0.9079 - val_loss: 0.2650 - val_acc: 0.9050\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.2423 - acc: 0.9142 - val_loss: 0.2335 - val_acc: 0.9178\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.2272 - acc: 0.9184 - val_loss: 0.2457 - val_acc: 0.9127\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.2123 - acc: 0.9234 - val_loss: 0.2254 - val_acc: 0.9214\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1998 - acc: 0.9287 - val_loss: 0.2243 - val_acc: 0.9230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0ebfad30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1881 - acc: 0.9314 - val_loss: 0.2101 - val_acc: 0.9270\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1753 - acc: 0.9362 - val_loss: 0.1913 - val_acc: 0.9338\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1707 - acc: 0.9380 - val_loss: 0.2064 - val_acc: 0.9291\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1570 - acc: 0.9438 - val_loss: 0.1977 - val_acc: 0.9312\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1567 - acc: 0.9428 - val_loss: 0.1824 - val_acc: 0.9376\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1420 - acc: 0.9480 - val_loss: 0.1919 - val_acc: 0.9358\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1342 - acc: 0.9506 - val_loss: 0.1856 - val_acc: 0.9373\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1313 - acc: 0.9519 - val_loss: 0.2004 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1229 - acc: 0.9562 - val_loss: 0.1984 - val_acc: 0.9350\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 5s - loss: 0.1192 - acc: 0.9552 - val_loss: 0.2071 - val_acc: 0.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0dea8860>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.239513599713\n",
      "Test accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 7s - loss: 0.4569 - acc: 0.8427 - val_loss: 0.3263 - val_acc: 0.8827\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 6s - loss: 0.3597 - acc: 0.8688 - val_loss: 0.3222 - val_acc: 0.8842\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 6s - loss: 0.3402 - acc: 0.8768 - val_loss: 0.2789 - val_acc: 0.8995\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 6s - loss: 0.3233 - acc: 0.8829 - val_loss: 0.2744 - val_acc: 0.9009\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 6s - loss: 0.3090 - acc: 0.8894 - val_loss: 0.2834 - val_acc: 0.8992\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 6s - loss: 0.3091 - acc: 0.8880 - val_loss: 0.2749 - val_acc: 0.8991\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 6s - loss: 0.3000 - acc: 0.8918 - val_loss: 0.2589 - val_acc: 0.9056\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 6s - loss: 0.2883 - acc: 0.8963 - val_loss: 0.2549 - val_acc: 0.9079\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 6s - loss: 0.2906 - acc: 0.8939 - val_loss: 0.2541 - val_acc: 0.9084\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 6s - loss: 0.2881 - acc: 0.8962 - val_loss: 0.2586 - val_acc: 0.9065\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 6s - loss: 0.2837 - acc: 0.8971 - val_loss: 0.2782 - val_acc: 0.9019\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 6s - loss: 0.2740 - acc: 0.8998 - val_loss: 0.2354 - val_acc: 0.9142\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 6s - loss: 0.2773 - acc: 0.8998 - val_loss: 0.2586 - val_acc: 0.9047\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 6s - loss: 0.2705 - acc: 0.9016 - val_loss: 0.2306 - val_acc: 0.9164\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 6s - loss: 0.2662 - acc: 0.9020 - val_loss: 0.2401 - val_acc: 0.9141\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 6s - loss: 0.2643 - acc: 0.9055 - val_loss: 0.2393 - val_acc: 0.9127\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 6s - loss: 0.2613 - acc: 0.9046 - val_loss: 0.2363 - val_acc: 0.9140\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 6s - loss: 0.2594 - acc: 0.9070 - val_loss: 0.2379 - val_acc: 0.9183\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 6s - loss: 0.2566 - acc: 0.9072 - val_loss: 0.2533 - val_acc: 0.9110\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 6s - loss: 0.2528 - acc: 0.9079 - val_loss: 0.2258 - val_acc: 0.9195\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 6s - loss: 0.2514 - acc: 0.9089 - val_loss: 0.2231 - val_acc: 0.9193\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 6s - loss: 0.2485 - acc: 0.9090 - val_loss: 0.2231 - val_acc: 0.9219\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 6s - loss: 0.2475 - acc: 0.9097 - val_loss: 0.2255 - val_acc: 0.9160\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 6s - loss: 0.2506 - acc: 0.9087 - val_loss: 0.2193 - val_acc: 0.9214\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 6s - loss: 0.2423 - acc: 0.9122 - val_loss: 0.2204 - val_acc: 0.9198\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 6s - loss: 0.2466 - acc: 0.9114 - val_loss: 0.2260 - val_acc: 0.9184\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 6s - loss: 0.2466 - acc: 0.9109 - val_loss: 0.2190 - val_acc: 0.9198\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 6s - loss: 0.2416 - acc: 0.9131 - val_loss: 0.2286 - val_acc: 0.9179\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 6s - loss: 0.2394 - acc: 0.9131 - val_loss: 0.2235 - val_acc: 0.9209\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 6s - loss: 0.2308 - acc: 0.9162 - val_loss: 0.2232 - val_acc: 0.9185\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 6s - loss: 0.2370 - acc: 0.9134 - val_loss: 0.2037 - val_acc: 0.9250\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 6s - loss: 0.2301 - acc: 0.9154 - val_loss: 0.2169 - val_acc: 0.9228\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 6s - loss: 0.2315 - acc: 0.9155 - val_loss: 0.2172 - val_acc: 0.9211\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 6s - loss: 0.2280 - acc: 0.9172 - val_loss: 0.2191 - val_acc: 0.9213\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 6s - loss: 0.2302 - acc: 0.9157 - val_loss: 0.2095 - val_acc: 0.9261\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 6s - loss: 0.2227 - acc: 0.9192 - val_loss: 0.2259 - val_acc: 0.9201\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 6s - loss: 0.2275 - acc: 0.9164 - val_loss: 0.2080 - val_acc: 0.9260\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 6s - loss: 0.2257 - acc: 0.9176 - val_loss: 0.2092 - val_acc: 0.9281\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 6s - loss: 0.2234 - acc: 0.9197 - val_loss: 0.2032 - val_acc: 0.9294\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 6s - loss: 0.2223 - acc: 0.9191 - val_loss: 0.2255 - val_acc: 0.9201\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 6s - loss: 0.2234 - acc: 0.9208 - val_loss: 0.2109 - val_acc: 0.9254\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 6s - loss: 0.2185 - acc: 0.9216 - val_loss: 0.2096 - val_acc: 0.9240\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 6s - loss: 0.2120 - acc: 0.9232 - val_loss: 0.2235 - val_acc: 0.9230\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 6s - loss: 0.2155 - acc: 0.9213 - val_loss: 0.2136 - val_acc: 0.9251\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 6s - loss: 0.2165 - acc: 0.9223 - val_loss: 0.2199 - val_acc: 0.9226\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 6s - loss: 0.2168 - acc: 0.9206 - val_loss: 0.2117 - val_acc: 0.9243\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 6s - loss: 0.2140 - acc: 0.9228 - val_loss: 0.2175 - val_acc: 0.9243\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 6s - loss: 0.2112 - acc: 0.9234 - val_loss: 0.2141 - val_acc: 0.9249\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 6s - loss: 0.2082 - acc: 0.9245 - val_loss: 0.2084 - val_acc: 0.9247\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 6s - loss: 0.2127 - acc: 0.9222 - val_loss: 0.2031 - val_acc: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0da7ab70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.188260396481\n",
      "Test accuracy: 0.9354\n"
     ]
    }
   ],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Like Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s - loss: 1.1620 - acc: 0.5509 - val_loss: 0.5807 - val_acc: 0.7721\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.5223 - acc: 0.8059 - val_loss: 0.4136 - val_acc: 0.8458\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.3864 - acc: 0.8613 - val_loss: 0.2957 - val_acc: 0.8952\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.3172 - acc: 0.8871 - val_loss: 0.3052 - val_acc: 0.8885\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.2787 - acc: 0.9008 - val_loss: 0.2342 - val_acc: 0.9158\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.2430 - acc: 0.9131 - val_loss: 0.2404 - val_acc: 0.9127\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.2172 - acc: 0.9227 - val_loss: 0.2469 - val_acc: 0.9091\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1968 - acc: 0.9295 - val_loss: 0.2172 - val_acc: 0.9247\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1775 - acc: 0.9363 - val_loss: 0.2124 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1616 - acc: 0.9430 - val_loss: 0.2285 - val_acc: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0d36a7f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1584 - acc: 0.9442 - val_loss: 0.2155 - val_acc: 0.9267\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1319 - acc: 0.9526 - val_loss: 0.2024 - val_acc: 0.9305\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1228 - acc: 0.9567 - val_loss: 0.2117 - val_acc: 0.9301\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.1096 - acc: 0.9611 - val_loss: 0.2452 - val_acc: 0.9255\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0986 - acc: 0.9651 - val_loss: 0.2530 - val_acc: 0.9255\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0896 - acc: 0.9675 - val_loss: 0.2428 - val_acc: 0.9273\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0835 - acc: 0.9711 - val_loss: 0.2585 - val_acc: 0.9183\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0807 - acc: 0.9721 - val_loss: 0.2648 - val_acc: 0.9243\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0709 - acc: 0.9757 - val_loss: 0.2641 - val_acc: 0.9246\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 3s - loss: 0.0609 - acc: 0.9792 - val_loss: 0.2733 - val_acc: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0d36a6d8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.334026500632\n",
      "Test accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "score = cnn4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 7s - loss: 0.3967 - acc: 0.8585 - val_loss: 0.3305 - val_acc: 0.8817\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 6s - loss: 0.3177 - acc: 0.8850 - val_loss: 0.2868 - val_acc: 0.8943\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 6s - loss: 0.2959 - acc: 0.8916 - val_loss: 0.2782 - val_acc: 0.8997\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 6s - loss: 0.2750 - acc: 0.8993 - val_loss: 0.2831 - val_acc: 0.8998\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 6s - loss: 0.2683 - acc: 0.9019 - val_loss: 0.2666 - val_acc: 0.9006\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 6s - loss: 0.2647 - acc: 0.9048 - val_loss: 0.2718 - val_acc: 0.9016\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 6s - loss: 0.2559 - acc: 0.9077 - val_loss: 0.2533 - val_acc: 0.9083\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 6s - loss: 0.2460 - acc: 0.9118 - val_loss: 0.2505 - val_acc: 0.9098\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 6s - loss: 0.2431 - acc: 0.9110 - val_loss: 0.2588 - val_acc: 0.9079\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 6s - loss: 0.2345 - acc: 0.9147 - val_loss: 0.2492 - val_acc: 0.9082\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 6s - loss: 0.2308 - acc: 0.9148 - val_loss: 0.2551 - val_acc: 0.9057\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 6s - loss: 0.2293 - acc: 0.9151 - val_loss: 0.2639 - val_acc: 0.9021\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 6s - loss: 0.2217 - acc: 0.9187 - val_loss: 0.2338 - val_acc: 0.9147\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 6s - loss: 0.2196 - acc: 0.9192 - val_loss: 0.2344 - val_acc: 0.9149\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 6s - loss: 0.2181 - acc: 0.9213 - val_loss: 0.2492 - val_acc: 0.9109\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 6s - loss: 0.2144 - acc: 0.9224 - val_loss: 0.2393 - val_acc: 0.9164\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 6s - loss: 0.2114 - acc: 0.9228 - val_loss: 0.2315 - val_acc: 0.9151\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 6s - loss: 0.2052 - acc: 0.9261 - val_loss: 0.2350 - val_acc: 0.9182\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 6s - loss: 0.2023 - acc: 0.9247 - val_loss: 0.2437 - val_acc: 0.9113\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 6s - loss: 0.2019 - acc: 0.9258 - val_loss: 0.2239 - val_acc: 0.9179\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 6s - loss: 0.1971 - acc: 0.9275 - val_loss: 0.2308 - val_acc: 0.9188\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 6s - loss: 0.1920 - acc: 0.9306 - val_loss: 0.2253 - val_acc: 0.9204\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 6s - loss: 0.1959 - acc: 0.9270 - val_loss: 0.2286 - val_acc: 0.9192\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 6s - loss: 0.1920 - acc: 0.9305 - val_loss: 0.2180 - val_acc: 0.9247\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 6s - loss: 0.1841 - acc: 0.9336 - val_loss: 0.2269 - val_acc: 0.9213\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 6s - loss: 0.1821 - acc: 0.9338 - val_loss: 0.2240 - val_acc: 0.9203\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 6s - loss: 0.1828 - acc: 0.9332 - val_loss: 0.2176 - val_acc: 0.9240\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 6s - loss: 0.1797 - acc: 0.9347 - val_loss: 0.2208 - val_acc: 0.9231\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 6s - loss: 0.1759 - acc: 0.9353 - val_loss: 0.2167 - val_acc: 0.9243\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 6s - loss: 0.1742 - acc: 0.9359 - val_loss: 0.2223 - val_acc: 0.9212\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 6s - loss: 0.1770 - acc: 0.9359 - val_loss: 0.2138 - val_acc: 0.9252\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 6s - loss: 0.1741 - acc: 0.9366 - val_loss: 0.2222 - val_acc: 0.9243\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 6s - loss: 0.1761 - acc: 0.9362 - val_loss: 0.2237 - val_acc: 0.9243\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 6s - loss: 0.1721 - acc: 0.9367 - val_loss: 0.2379 - val_acc: 0.9192\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 6s - loss: 0.1700 - acc: 0.9388 - val_loss: 0.2586 - val_acc: 0.9165\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 6s - loss: 0.1688 - acc: 0.9379 - val_loss: 0.2301 - val_acc: 0.9246\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 6s - loss: 0.1623 - acc: 0.9408 - val_loss: 0.2289 - val_acc: 0.9229\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 6s - loss: 0.1599 - acc: 0.9416 - val_loss: 0.2339 - val_acc: 0.9186\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 6s - loss: 0.1685 - acc: 0.9394 - val_loss: 0.2205 - val_acc: 0.9230\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 6s - loss: 0.1547 - acc: 0.9433 - val_loss: 0.2132 - val_acc: 0.9253\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 6s - loss: 0.1576 - acc: 0.9417 - val_loss: 0.2412 - val_acc: 0.9207\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 6s - loss: 0.1611 - acc: 0.9409 - val_loss: 0.2170 - val_acc: 0.9265\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 6s - loss: 0.1576 - acc: 0.9423 - val_loss: 0.2217 - val_acc: 0.9259\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 7s - loss: 0.1589 - acc: 0.9422 - val_loss: 0.2390 - val_acc: 0.9197\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 6s - loss: 0.1543 - acc: 0.9445 - val_loss: 0.2337 - val_acc: 0.9207\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 6s - loss: 0.1480 - acc: 0.9457 - val_loss: 0.2172 - val_acc: 0.9267\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 6s - loss: 0.1498 - acc: 0.9436 - val_loss: 0.2226 - val_acc: 0.9230\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 6s - loss: 0.1492 - acc: 0.9463 - val_loss: 0.2413 - val_acc: 0.9227\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 6s - loss: 0.1502 - acc: 0.9462 - val_loss: 0.2225 - val_acc: 0.9283\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 6s - loss: 0.1499 - acc: 0.9453 - val_loss: 0.2208 - val_acc: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0cf38f60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.193522232082\n",
      "Test accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "score = cnn4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Like Model With Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.8053 - acc: 0.7310 - val_loss: 2.8340 - val_acc: 0.1061\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.4330 - acc: 0.8426 - val_loss: 3.4900 - val_acc: 0.3552\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.3449 - acc: 0.8752 - val_loss: 4.8988 - val_acc: 0.1126\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2972 - acc: 0.8927 - val_loss: 2.3724 - val_acc: 0.4153\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2636 - acc: 0.9033 - val_loss: 0.3967 - val_acc: 0.8660\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2409 - acc: 0.9116 - val_loss: 0.4278 - val_acc: 0.8573\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2278 - acc: 0.9169 - val_loss: 0.2007 - val_acc: 0.9286\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2058 - acc: 0.9254 - val_loss: 0.1954 - val_acc: 0.9310\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1975 - acc: 0.9268 - val_loss: 0.2283 - val_acc: 0.9186\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1852 - acc: 0.9319 - val_loss: 0.1994 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb04d14eb8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn5.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1748 - acc: 0.9360 - val_loss: 0.1984 - val_acc: 0.9331\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1652 - acc: 0.9395 - val_loss: 0.1965 - val_acc: 0.9376\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1572 - acc: 0.9425 - val_loss: 0.1781 - val_acc: 0.9401\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1454 - acc: 0.9464 - val_loss: 0.1759 - val_acc: 0.9392\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1350 - acc: 0.9499 - val_loss: 0.2181 - val_acc: 0.9338\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1277 - acc: 0.9527 - val_loss: 0.1997 - val_acc: 0.9358\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1226 - acc: 0.9551 - val_loss: 0.1930 - val_acc: 0.9394\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1119 - acc: 0.9577 - val_loss: 0.2257 - val_acc: 0.9315\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.1055 - acc: 0.9606 - val_loss: 0.2066 - val_acc: 0.9375\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.0970 - acc: 0.9645 - val_loss: 0.1986 - val_acc: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0c9a20b8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn5.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.227945802512\n",
      "Test accuracy: 0.9296\n"
     ]
    }
   ],
   "source": [
    "score = cnn5.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 16s - loss: 0.3573 - acc: 0.8742 - val_loss: 0.3032 - val_acc: 0.8989\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 16s - loss: 0.2950 - acc: 0.8938 - val_loss: 0.2749 - val_acc: 0.9000\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 16s - loss: 0.2756 - acc: 0.8995 - val_loss: 0.3022 - val_acc: 0.8914\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 16s - loss: 0.2672 - acc: 0.9036 - val_loss: 0.2442 - val_acc: 0.9126\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 16s - loss: 0.2559 - acc: 0.9067 - val_loss: 0.2618 - val_acc: 0.9051\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 16s - loss: 0.2493 - acc: 0.9094 - val_loss: 0.2671 - val_acc: 0.9079\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 16s - loss: 0.2421 - acc: 0.9113 - val_loss: 0.2532 - val_acc: 0.9067\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 16s - loss: 0.2375 - acc: 0.9128 - val_loss: 0.2315 - val_acc: 0.9194\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 16s - loss: 0.2337 - acc: 0.9141 - val_loss: 0.2346 - val_acc: 0.9173\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 16s - loss: 0.2290 - acc: 0.9152 - val_loss: 0.2551 - val_acc: 0.9107\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 16s - loss: 0.2186 - acc: 0.9194 - val_loss: 0.2457 - val_acc: 0.9092\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 16s - loss: 0.2200 - acc: 0.9189 - val_loss: 0.2460 - val_acc: 0.9136\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 16s - loss: 0.2124 - acc: 0.9217 - val_loss: 0.2248 - val_acc: 0.9219\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 16s - loss: 0.2141 - acc: 0.9219 - val_loss: 0.2121 - val_acc: 0.9239\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 16s - loss: 0.2051 - acc: 0.9241 - val_loss: 0.2335 - val_acc: 0.9191\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 16s - loss: 0.2059 - acc: 0.9237 - val_loss: 0.2222 - val_acc: 0.9214\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 16s - loss: 0.2066 - acc: 0.9246 - val_loss: 0.2112 - val_acc: 0.9231\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 16s - loss: 0.1977 - acc: 0.9272 - val_loss: 0.2345 - val_acc: 0.9187\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 16s - loss: 0.1955 - acc: 0.9270 - val_loss: 0.1980 - val_acc: 0.9296\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 16s - loss: 0.1965 - acc: 0.9284 - val_loss: 0.2066 - val_acc: 0.9281\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 16s - loss: 0.1901 - acc: 0.9307 - val_loss: 0.2169 - val_acc: 0.9251\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 16s - loss: 0.1913 - acc: 0.9296 - val_loss: 0.2052 - val_acc: 0.9277\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 16s - loss: 0.1824 - acc: 0.9333 - val_loss: 0.2103 - val_acc: 0.9266\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 16s - loss: 0.1897 - acc: 0.9308 - val_loss: 0.2338 - val_acc: 0.9162\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 16s - loss: 0.1798 - acc: 0.9346 - val_loss: 0.2226 - val_acc: 0.9222\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 16s - loss: 0.1856 - acc: 0.9323 - val_loss: 0.2038 - val_acc: 0.9277\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 16s - loss: 0.1815 - acc: 0.9346 - val_loss: 0.2009 - val_acc: 0.9314\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 16s - loss: 0.1704 - acc: 0.9374 - val_loss: 0.2132 - val_acc: 0.9288\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 16s - loss: 0.1742 - acc: 0.9362 - val_loss: 0.2063 - val_acc: 0.9265\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 16s - loss: 0.1670 - acc: 0.9390 - val_loss: 0.2060 - val_acc: 0.9282\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 16s - loss: 0.1638 - acc: 0.9386 - val_loss: 0.1994 - val_acc: 0.9351\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 16s - loss: 0.1666 - acc: 0.9396 - val_loss: 0.2001 - val_acc: 0.9327\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 16s - loss: 0.1610 - acc: 0.9406 - val_loss: 0.2188 - val_acc: 0.9240\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 16s - loss: 0.1623 - acc: 0.9409 - val_loss: 0.1985 - val_acc: 0.9313\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 16s - loss: 0.1562 - acc: 0.9429 - val_loss: 0.2299 - val_acc: 0.9256\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 16s - loss: 0.1640 - acc: 0.9402 - val_loss: 0.2170 - val_acc: 0.9226\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 16s - loss: 0.1560 - acc: 0.9429 - val_loss: 0.1942 - val_acc: 0.9337\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 16s - loss: 0.1601 - acc: 0.9414 - val_loss: 0.2054 - val_acc: 0.9302\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 16s - loss: 0.1503 - acc: 0.9444 - val_loss: 0.1953 - val_acc: 0.9323\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 16s - loss: 0.1502 - acc: 0.9443 - val_loss: 0.2039 - val_acc: 0.9342\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 16s - loss: 0.1455 - acc: 0.9459 - val_loss: 0.2034 - val_acc: 0.9319\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 16s - loss: 0.1521 - acc: 0.9439 - val_loss: 0.1959 - val_acc: 0.9346\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 16s - loss: 0.1422 - acc: 0.9482 - val_loss: 0.2070 - val_acc: 0.9322\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 16s - loss: 0.1407 - acc: 0.9479 - val_loss: 0.2077 - val_acc: 0.9314\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 16s - loss: 0.1381 - acc: 0.9498 - val_loss: 0.2056 - val_acc: 0.9327\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 16s - loss: 0.1377 - acc: 0.9490 - val_loss: 0.2174 - val_acc: 0.9277\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 16s - loss: 0.1374 - acc: 0.9490 - val_loss: 0.2012 - val_acc: 0.9341\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 16s - loss: 0.1331 - acc: 0.9508 - val_loss: 0.2001 - val_acc: 0.9338\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 16s - loss: 0.1390 - acc: 0.9493 - val_loss: 0.1798 - val_acc: 0.9403\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 16s - loss: 0.1328 - acc: 0.9514 - val_loss: 0.1904 - val_acc: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb04772048>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn5.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.177969511382\n",
      "Test accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "score = cnn5.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
